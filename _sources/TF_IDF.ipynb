{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk9Q73XMgd_Q"
      },
      "source": [
        "# TF-IDF & Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WEHhGE7ejcS"
      },
      "source": [
        "### TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNBjnzFQOabr",
        "outputId": "e05da043-81a1-4aae-9abd-70ca4958d321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /home/codespace/.local/lib/python3.12/site-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ux38ohqmOdP0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ntbuDRxD7bjh",
        "outputId": "5370a8ee-44a0-433e-9ace-5b7b6b9a2045"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_berita</th>\n",
              "      <th>judul_berita</th>\n",
              "      <th>isi_berita</th>\n",
              "      <th>kategori_berita</th>\n",
              "      <th>judul_clean</th>\n",
              "      <th>isi_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2070813</td>\n",
              "      <td>RUU Perampasan Aset Diupayakan Tak Cuma Akomod...</td>\n",
              "      <td>KETUA Badan Legislasi DPR Bob Hasan mengatakan...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['ruu', 'ampas', 'aset', 'upaya', 'akomodasi',...</td>\n",
              "      <td>['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2070810</td>\n",
              "      <td>Debat Sengit Komisi II DPR dan Baleg Berebut B...</td>\n",
              "      <td>SUASANA rapat koordinasi antara pimpinan komis...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['debat', 'sengit', 'komisi', 'ii', 'dpr', 'ba...</td>\n",
              "      <td>['suasana', 'rapat', 'koordinasi', 'pimpin', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2070792</td>\n",
              "      <td>Sengketa Pilkada Ulang Barito Utara dan Papua ...</td>\n",
              "      <td>MAHKAMAH Konstitusi (MK) menyelesaikan Permoho...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['sengketa', 'pilkada', 'ulang', 'barito', 'ut...</td>\n",
              "      <td>['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2070783</td>\n",
              "      <td>Respons Pemerintah dan Tentara soal MK Tolak G...</td>\n",
              "      <td>WAKIL Menteri Hukum Eddy Hiariej menghormati p...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['respons', 'perintah', 'tentara', 'mk', 'tola...</td>\n",
              "      <td>['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2070782</td>\n",
              "      <td>Rangkap Jabatan Menpora dan Ketum PSSI, Erick ...</td>\n",
              "      <td>MENTERI Pemuda dan Olahraga Erick Thohir belum...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['rangkap', 'jabat', 'menpora', 'tum', 'pssi',...</td>\n",
              "      <td>['menteri', 'pemuda', 'olahraga', 'erick', 'th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_berita                                       judul_berita  \\\n",
              "0    2070813  RUU Perampasan Aset Diupayakan Tak Cuma Akomod...   \n",
              "1    2070810  Debat Sengit Komisi II DPR dan Baleg Berebut B...   \n",
              "2    2070792  Sengketa Pilkada Ulang Barito Utara dan Papua ...   \n",
              "3    2070783  Respons Pemerintah dan Tentara soal MK Tolak G...   \n",
              "4    2070782  Rangkap Jabatan Menpora dan Ketum PSSI, Erick ...   \n",
              "\n",
              "                                          isi_berita kategori_berita  \\\n",
              "0  KETUA Badan Legislasi DPR Bob Hasan mengatakan...         politik   \n",
              "1  SUASANA rapat koordinasi antara pimpinan komis...         politik   \n",
              "2  MAHKAMAH Konstitusi (MK) menyelesaikan Permoho...         politik   \n",
              "3  WAKIL Menteri Hukum Eddy Hiariej menghormati p...         politik   \n",
              "4  MENTERI Pemuda dan Olahraga Erick Thohir belum...         politik   \n",
              "\n",
              "                                         judul_clean  \\\n",
              "0  ['ruu', 'ampas', 'aset', 'upaya', 'akomodasi',...   \n",
              "1  ['debat', 'sengit', 'komisi', 'ii', 'dpr', 'ba...   \n",
              "2  ['sengketa', 'pilkada', 'ulang', 'barito', 'ut...   \n",
              "3  ['respons', 'perintah', 'tentara', 'mk', 'tola...   \n",
              "4  ['rangkap', 'jabat', 'menpora', 'tum', 'pssi',...   \n",
              "\n",
              "                                           isi_clean  \n",
              "0  ['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...  \n",
              "1  ['suasana', 'rapat', 'koordinasi', 'pimpin', '...  \n",
              "2  ['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...  \n",
              "3  ['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...  \n",
              "4  ['menteri', 'pemuda', 'olahraga', 'erick', 'th...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"preprocessing_berita.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "10frWSF87Xbw",
        "outputId": "5f2187d0-6a8b-45bf-e58a-a26980c690b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isi_clean</th>\n",
              "      <th>isi_clean_joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...</td>\n",
              "      <td>ketua badan legislasi dpr bob hasan draf naska...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['suasana', 'rapat', 'koordinasi', 'pimpin', '...</td>\n",
              "      <td>suasana rapat koordinasi pimpin komisi komisi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...</td>\n",
              "      <td>mahkamah konstitusi mk selesai mohon selisih h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...</td>\n",
              "      <td>wakil menteri hukum eddy hiariej hormat putus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['menteri', 'pemuda', 'olahraga', 'erick', 'th...</td>\n",
              "      <td>menteri pemuda olahraga erick thohir nasib ket...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           isi_clean  \\\n",
              "0  ['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...   \n",
              "1  ['suasana', 'rapat', 'koordinasi', 'pimpin', '...   \n",
              "2  ['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...   \n",
              "3  ['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...   \n",
              "4  ['menteri', 'pemuda', 'olahraga', 'erick', 'th...   \n",
              "\n",
              "                                    isi_clean_joined  \n",
              "0  ketua badan legislasi dpr bob hasan draf naska...  \n",
              "1  suasana rapat koordinasi pimpin komisi komisi ...  \n",
              "2  mahkamah konstitusi mk selesai mohon selisih h...  \n",
              "3  wakil menteri hukum eddy hiariej hormat putus ...  \n",
              "4  menteri pemuda olahraga erick thohir nasib ket...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[\"isi_clean_joined\"] = df[\"isi_clean\"].apply(\n",
        "    lambda x: \" \".join(ast.literal_eval(x)) if isinstance(x, str) else \"\"\n",
        ")\n",
        "\n",
        "\n",
        "df[[\"isi_clean\", \"isi_clean_joined\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "LF0qNxhOmyJ5",
        "outputId": "41ab8518-a512-4ac7-86ce-b6ac349fc02c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_berita</th>\n",
              "      <th>abdul</th>\n",
              "      <th>acara</th>\n",
              "      <th>acosta</th>\n",
              "      <th>ad</th>\n",
              "      <th>ada</th>\n",
              "      <th>adik</th>\n",
              "      <th>adil</th>\n",
              "      <th>adnan</th>\n",
              "      <th>adu</th>\n",
              "      <th>...</th>\n",
              "      <th>wira</th>\n",
              "      <th>wisata</th>\n",
              "      <th>wisatawan</th>\n",
              "      <th>wta</th>\n",
              "      <th>yamaha</th>\n",
              "      <th>yogyakarta</th>\n",
              "      <th>york</th>\n",
              "      <th>yu</th>\n",
              "      <th>zetro</th>\n",
              "      <th>zona</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2070813</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2070810</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2070792</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2070783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042812</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2070782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2070778</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2070771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2070768</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2070766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2070760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 1001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_berita  abdul  acara  acosta   ad  ada  adik      adil  adnan  adu  ...  \\\n",
              "0    2070813    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "1    2070810    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "2    2070792    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "3    2070783    0.0    0.0     0.0  0.0  0.0   0.0  0.042812    0.0  0.0  ...   \n",
              "4    2070782    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "5    2070778    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "6    2070771    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "7    2070768    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "8    2070766    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "9    2070760    0.0    0.0     0.0  0.0  0.0   0.0  0.000000    0.0  0.0  ...   \n",
              "\n",
              "   wira  wisata  wisatawan  wta  yamaha  yogyakarta  york   yu  zetro  zona  \n",
              "0   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "1   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "2   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "3   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "4   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "5   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "6   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "7   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "8   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "9   0.0     0.0        0.0  0.0     0.0         0.0   0.0  0.0    0.0   0.0  \n",
              "\n",
              "[10 rows x 1001 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# load CSV\n",
        "df = pd.read_csv(\"preprocessing_berita.csv\")\n",
        "\n",
        "# pakai kolom isi_clean yang ada\n",
        "df[\"isi_clean\"] = df[\"isi_clean\"].fillna(\"\")\n",
        "\n",
        "# Inisialisasi TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=1000)  # ambil 1000 fitur teratas\n",
        "\n",
        "# Fit dan transform\n",
        "X_tfidf = vectorizer.fit_transform(df[\"isi_clean\"])\n",
        "\n",
        "# Buat DataFrame TF-IDF\n",
        "tfidf_df = pd.DataFrame(\n",
        "    X_tfidf.toarray(),\n",
        "    columns=vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Tambahkan kolom id_berita di depan\n",
        "tfidf_df.insert(0, \"id_berita\", df[\"id_berita\"].values)\n",
        "\n",
        "# Lihat hasilnya\n",
        "display(tfidf_df.head(10))\n",
        "\n",
        "# Kalau mau simpan ke file CSV\n",
        "tfidf_df.to_csv(\"TFIDF_Berita.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI6DbiF7nl7G"
      },
      "source": [
        "### Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X84LTx_EoF7g",
        "outputId": "b95aa142-124e-4cb9-c525-57024e0b540a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/python/3.12.1/lib/python3.12/site-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/python/3.12.1/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9Q8Ao_AmrBKF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "v97MVIYxqsn2",
        "outputId": "bf12cb17-f999-4b64-ed36-31ed0d81e324"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_berita</th>\n",
              "      <th>judul_berita</th>\n",
              "      <th>isi_berita</th>\n",
              "      <th>kategori_berita</th>\n",
              "      <th>judul_clean</th>\n",
              "      <th>isi_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2070813</td>\n",
              "      <td>RUU Perampasan Aset Diupayakan Tak Cuma Akomod...</td>\n",
              "      <td>KETUA Badan Legislasi DPR Bob Hasan mengatakan...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['ruu', 'ampas', 'aset', 'upaya', 'akomodasi',...</td>\n",
              "      <td>['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2070810</td>\n",
              "      <td>Debat Sengit Komisi II DPR dan Baleg Berebut B...</td>\n",
              "      <td>SUASANA rapat koordinasi antara pimpinan komis...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['debat', 'sengit', 'komisi', 'ii', 'dpr', 'ba...</td>\n",
              "      <td>['suasana', 'rapat', 'koordinasi', 'pimpin', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2070792</td>\n",
              "      <td>Sengketa Pilkada Ulang Barito Utara dan Papua ...</td>\n",
              "      <td>MAHKAMAH Konstitusi (MK) menyelesaikan Permoho...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['sengketa', 'pilkada', 'ulang', 'barito', 'ut...</td>\n",
              "      <td>['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2070783</td>\n",
              "      <td>Respons Pemerintah dan Tentara soal MK Tolak G...</td>\n",
              "      <td>WAKIL Menteri Hukum Eddy Hiariej menghormati p...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['respons', 'perintah', 'tentara', 'mk', 'tola...</td>\n",
              "      <td>['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2070782</td>\n",
              "      <td>Rangkap Jabatan Menpora dan Ketum PSSI, Erick ...</td>\n",
              "      <td>MENTERI Pemuda dan Olahraga Erick Thohir belum...</td>\n",
              "      <td>politik</td>\n",
              "      <td>['rangkap', 'jabat', 'menpora', 'tum', 'pssi',...</td>\n",
              "      <td>['menteri', 'pemuda', 'olahraga', 'erick', 'th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_berita                                       judul_berita  \\\n",
              "0    2070813  RUU Perampasan Aset Diupayakan Tak Cuma Akomod...   \n",
              "1    2070810  Debat Sengit Komisi II DPR dan Baleg Berebut B...   \n",
              "2    2070792  Sengketa Pilkada Ulang Barito Utara dan Papua ...   \n",
              "3    2070783  Respons Pemerintah dan Tentara soal MK Tolak G...   \n",
              "4    2070782  Rangkap Jabatan Menpora dan Ketum PSSI, Erick ...   \n",
              "\n",
              "                                          isi_berita kategori_berita  \\\n",
              "0  KETUA Badan Legislasi DPR Bob Hasan mengatakan...         politik   \n",
              "1  SUASANA rapat koordinasi antara pimpinan komis...         politik   \n",
              "2  MAHKAMAH Konstitusi (MK) menyelesaikan Permoho...         politik   \n",
              "3  WAKIL Menteri Hukum Eddy Hiariej menghormati p...         politik   \n",
              "4  MENTERI Pemuda dan Olahraga Erick Thohir belum...         politik   \n",
              "\n",
              "                                         judul_clean  \\\n",
              "0  ['ruu', 'ampas', 'aset', 'upaya', 'akomodasi',...   \n",
              "1  ['debat', 'sengit', 'komisi', 'ii', 'dpr', 'ba...   \n",
              "2  ['sengketa', 'pilkada', 'ulang', 'barito', 'ut...   \n",
              "3  ['respons', 'perintah', 'tentara', 'mk', 'tola...   \n",
              "4  ['rangkap', 'jabat', 'menpora', 'tum', 'pssi',...   \n",
              "\n",
              "                                           isi_clean  \n",
              "0  ['ketua', 'badan', 'legislasi', 'dpr', 'bob', ...  \n",
              "1  ['suasana', 'rapat', 'koordinasi', 'pimpin', '...  \n",
              "2  ['mahkamah', 'konstitusi', 'mk', 'selesai', 'm...  \n",
              "3  ['wakil', 'menteri', 'hukum', 'eddy', 'hiariej...  \n",
              "4  ['menteri', 'pemuda', 'olahraga', 'erick', 'th...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"preprocessing_berita.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRZL5iwVq2ac",
        "outputId": "6cf5182d-1a61-4cb1-b2a4-643496f05956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vektor untuk kata 'indonesia':\n",
            "[-0.02884256  0.32666102 -0.2997007  -0.30499357  0.4139644  -0.07996126\n",
            "  0.034549   -0.24059972 -0.36235732 -0.17398427]\n",
            "\n",
            "Kata yang mirip dengan 'indonesia':\n",
            "[('garuda', 0.7596750259399414), ('bola', 0.7428099513053894), ('sepak', 0.7375729084014893), ('bulu', 0.7346426248550415), ('rakyat', 0.7300464510917664)]\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# 1. Membuat korpus (list of lists kata)\n",
        "# ===============================\n",
        "corpus = df[\"isi_clean\"].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []  # Ubah string list menjadi list Python, atau [] jika kosong\n",
        ").tolist()  # Hasil akhir: list of lists (setiap berita menjadi satu list kata)\n",
        "\n",
        "# ===============================\n",
        "# 2. Membuat dan melatih Word2Vec (semua kata)\n",
        "# ===============================\n",
        "model = Word2Vec(\n",
        "    sentences=corpus,   # Input list of lists kata\n",
        "    vector_size=100,    # Dimensi vektor untuk tiap kata\n",
        "    window=5,           # Ukuran konteks: seberapa jauh kata tetangga diperhitungkan\n",
        "    min_count=1,        # Ambil semua kata, termasuk yang muncul sekali\n",
        "    sg=1,               # 1 = skip-gram, 0 = CBOW\n",
        "    workers=4           # Jumlah core CPU untuk paralelisasi\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 3. Simpan model\n",
        "# ===============================\n",
        "model.save(\"word2vec_berita.model\")  # Simpan model ke file .model agar bisa dipakai lagi nanti\n",
        "\n",
        "# ===============================\n",
        "# 4. Cek hasil Word Embedding\n",
        "# ===============================\n",
        "print(\"\\nVektor untuk kata 'indonesia':\")\n",
        "print(model.wv['indonesia'][:10])  # Menampilkan 10 elemen pertama dari vektor kata\n",
        "\n",
        "print(\"\\nKata yang mirip dengan 'indonesia':\")\n",
        "print(model.wv.most_similar(\"indonesia\", topn=5))  # Menampilkan 5 kata paling mirip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ-1xjPZ06f9"
      },
      "source": [
        "### Klasifikasi TF-IDF & Word Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aywqLPC76H_l"
      },
      "source": [
        "#### Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QwCPsYfx5jfr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sBqCl05e5l09"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fyixnS_v5nkc"
      },
      "outputs": [],
      "source": [
        "# Gabungkan token untuk TF-IDF\n",
        "df[\"isi_clean_joined\"] = df[\"isi_clean\"].apply(\n",
        "    lambda x: \" \".join(ast.literal_eval(x)) if isinstance(x, str) else \"\"\n",
        ")\n",
        "\n",
        "# Buat list of tokens untuk Word2Vec\n",
        "corpus = df[\"isi_clean\"].apply(\n",
        "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
        ").tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2sRFmnnF5qGb"
      },
      "outputs": [],
      "source": [
        "X_text = df[\"isi_clean_joined\"]\n",
        "y = df[\"kategori_berita\"]\n",
        "\n",
        "# === Split data (train/test) ===\n",
        "X_train, X_test, y_train, y_test, corpus_train, corpus_test = train_test_split(\n",
        "    X_text, y, corpus, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9loSXR8o5sRO",
        "outputId": "9243313a-2a2c-45df-bc57-dbad1e487952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Hasil TF-IDF + Naive Bayes ===\n",
            "Akurasi: 0.8785714285714286\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      ekonomi       0.83      0.90      0.86        21\n",
            "      hiburan       1.00      0.80      0.89        20\n",
            "        hukum       0.90      0.82      0.86        22\n",
            "internasional       0.88      1.00      0.93        14\n",
            "     olahraga       1.00      0.85      0.92        20\n",
            "     otomotif       0.86      1.00      0.92        18\n",
            "      politik       0.78      0.84      0.81        25\n",
            "\n",
            "     accuracy                           0.88       140\n",
            "    macro avg       0.89      0.89      0.88       140\n",
            " weighted avg       0.89      0.88      0.88       140\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Naive Bayes (cocok untuk teks)\n",
        "model_tfidf = MultinomialNB()\n",
        "model_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"=== Hasil TF-IDF + Naive Bayes ===\")\n",
        "print(\"Akurasi:\", accuracy_score(y_test, y_pred_tfidf))\n",
        "print(classification_report(y_test, y_pred_tfidf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr1ME5sI535k",
        "outputId": "8b8dd1fa-260f-46ed-fb8b-5fc3fd79b81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Hasil Word2Vec + Logistic Regression ===\n",
            "Akurasi: 0.8357142857142857\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      ekonomi       0.86      0.90      0.88        21\n",
            "      hiburan       0.89      0.85      0.87        20\n",
            "        hukum       0.80      0.73      0.76        22\n",
            "internasional       0.74      1.00      0.85        14\n",
            "     olahraga       1.00      0.85      0.92        20\n",
            "     otomotif       0.85      0.94      0.89        18\n",
            "      politik       0.74      0.68      0.71        25\n",
            "\n",
            "     accuracy                           0.84       140\n",
            "    macro avg       0.84      0.85      0.84       140\n",
            " weighted avg       0.84      0.84      0.83       140\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train Word2Vec dari corpus train\n",
        "w2v_model = Word2Vec(sentences=corpus_train, vector_size=100, window=5, min_count=2, sg=1)\n",
        "\n",
        "# Fungsi untuk ubah dokumen jadi rata-rata embedding\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in w2v_model.wv]\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "    return np.mean(w2v_model.wv[doc], axis=0)\n",
        "\n",
        "# Transform ke vektor\n",
        "X_train_w2v = np.array([document_vector(doc) for doc in corpus_train])\n",
        "X_test_w2v = np.array([document_vector(doc) for doc in corpus_test])\n",
        "\n",
        "# Logistic Regression (cocok untuk dense vector)\n",
        "model_w2v = LogisticRegression(max_iter=1000)\n",
        "model_w2v.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred_w2v = model_w2v.predict(X_test_w2v)\n",
        "\n",
        "print(\"=== Hasil Word2Vec + Logistic Regression ===\")\n",
        "print(\"Akurasi:\", accuracy_score(y_test, y_pred_w2v))\n",
        "print(classification_report(y_test, y_pred_w2v))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53uQsuo26BqU",
        "outputId": "c684c578-60f6-48dd-fdea-0f3f218a6166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Perbandingan Akurasi ===\n",
            "TF-IDF + Naive Bayes        : 0.8786\n",
            "Word2Vec + LogisticReg      : 0.8357\n"
          ]
        }
      ],
      "source": [
        "acc_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
        "acc_w2v = accuracy_score(y_test, y_pred_w2v)\n",
        "\n",
        "print(\"\\n=== Perbandingan Akurasi ===\")\n",
        "print(f\"TF-IDF + Naive Bayes        : {acc_tfidf:.4f}\")\n",
        "print(f\"Word2Vec + LogisticReg      : {acc_w2v:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
